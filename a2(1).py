# -*- coding: utf-8 -*-
"""a2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n8egx0YHo4YGdKbYiK67cz02E2zOAsFO
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

def peganoticia():
    cnn = 'https://www.cnnbrasil.com.br/'
    response = requests.get(cnn, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(response.content, 'html.parser')

    noticias = []

    for bagulho in soup.find_all(['a', 'h2', 'h3']):
        texto = bagulho.get_text(strip=True)
        if texto and len(texto) > 30 and texto not in noticias:
            noticias.append(texto)

    if noticias:
        print("lista de notícias da página principal:")
        for i, noticia in enumerate(noticias, 1):
            print(f"{i}. {noticia}")

    return noticias
peganoticia()

import os
import pandas as pd

def salvosim(novanoti, arquivo='noticias_cnn.csv'):
    if os.path.exists(arquivo):
        dfanti = pd.read_csv(arquivo)
        notianti = set(dfanti['Notícias'].tolist())
    else:
        notianti = set()

    unic = [noticia for noticia in novanoti if noticia not in notianti]

    if unic:
        dfnovo = pd.DataFrame({'Notícias': unic})
        dfreal = pd.concat([dfanti, dfnovo], ignore_index=True) if notianti else dfnovo
        dfreal.to_csv(arquivo, index=False, encoding='utf-8-sig')
        print(f"{len(unic)} novas notícias foram adicionadas ao '{arquivo}'.")
    else:
        print("nenhuma nova notícia foi adcionada.")

noticias = peganoticia()
salvosim(noticias)

ignorar = {'de', 'em', 'que','para','sobre','novo','diz','veja','cnn','como','mais','ser','tem','nesta','até','entre','ter','das','quem','r','após','são','pode','à','se','2025','não','sim','por','na','do','no','da','dos','a','o','os','ele','ela','eles','elas','é','com','um','uma','e','ou','quer','ao'}

import re
import csv

def carregar_dados(arquivo):

    dados = []
    with open(arquivo, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            next(reader, None)
            for row in reader:
                if row:
                    dados.append(row[0])
            return dados

noticias_list = carregar_dados('noticias_cnn.csv')

def limpar_tokenizar(texto, ignorar_set):
    palavras = re.findall(r'\b\w+\b', texto.lower())
    return [p for p in palavras if p not in ignorar_set]


tokenized_noticias = []
for noticia in noticias_list:
    tokenized_noticias.append(limpar_tokenizar(noticia, ignorar))

print(tokenized_noticias)

from collections import Counter

palavrascont = Counter()
for frase in tokenized_noticias:
    palavrascont.update(frase)

top = palavrascont.most_common(10)

print(palavrascont)

print(top)

import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import streamlit as st
import string


df = pd.read_csv('noticias_cnn.csv')
df['Data'] = pd.to_datetime(df.get('Data', pd.Timestamp.now()))


def limpar_texto(texto):
    texto = texto.lower()
    texto = texto.translate(str.maketrans('', '', string.punctuation))
    palavras = texto.split()
    return [p for p in palavras if p not in ignorar and len(p) > 2]

st.title("Palavras mais frequentes nas notícias CNN")

modo = st.radio("Modo de análise:", ["Geral", "Por dia"])
grafico = st.radio("Tipo de gráfico:", ["Colunas", "Barras horizontais"])
qtd = st.slider("Quantidade de palavras:", 5, 30, 10)

if modo == "Por dia":
    datas_disponiveis = df['Data'].dt.date.unique()
    data_escolhida = st.date_input("Escolha a data:", value=datas_disponiveis[0])
    df_filtrado = df[df['Data'].dt.date == data_escolhida]
else:
    df_filtrado = df


todas = []
for texto in df_filtrado["Notícias"].dropna():
    todas.extend(limpar_texto(texto))

contagem = Counter(todas)
mais_comuns = contagem.most_common(qtd)

palavras, freq = zip(*mais_comuns)

fig, ax = plt.subplots()
if grafico == "Colunas":
    ax.bar(palavras, freq, color='skyblue')
    plt.xticks(rotation=45)
else:
    ax.barh(palavras, freq, color='salmon')
    ax.invert_yaxis()

st.pyplot(fig)

streamlit run