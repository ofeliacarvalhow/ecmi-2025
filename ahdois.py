# -*- coding: utf-8 -*-
"""a2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n8egx0YHo4YGdKbYiK67cz02E2zOAsFO
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

def peganoticia():
    cnn = 'https://www.cnnbrasil.com.br/'
    response = requests.get(cnn, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(response.content, 'html.parser')

    noticias = []

    for bagulho in soup.find_all(['a', 'h2', 'h3']):
        texto = bagulho.get_text(strip=True)
        if texto and len(texto) > 30 and texto not in noticias:
            noticias.append(texto)

    if noticias:
        print("lista de not√≠cias da p√°gina principal:")
        for i, noticia in enumerate(noticias, 1):
            print(f"{i}. {noticia}")

    return noticias
peganoticia()

import os
import pandas as pd

def salvosim(novanoti, arquivo='noticias_cnn.csv'):
    if os.path.exists(arquivo):
        dfanti = pd.read_csv(arquivo)
        notianti = set(dfanti['Not√≠cias'].tolist())
    else:
        notianti = set()

    unic = [noticia for noticia in novanoti if noticia not in notianti]

    if unic:
        dfnovo = pd.DataFrame({'Not√≠cias': unic})
        dfreal = pd.concat([dfanti, dfnovo], ignore_index=True) if notianti else dfnovo
        dfreal.to_csv(arquivo, index=False, encoding='utf-8-sig')
        print(f"{len(unic)} novas not√≠cias foram adicionadas ao '{arquivo}'.")
    else:
        print("nenhuma nova not√≠cia foi adcionada.")

noticias = peganoticia()
salvosim(noticias)

ignorar = {'de', 'em', 'que','para','sobre','novo','diz','veja','cnn','como','mais','ser','tem','nesta','at√©','entre','ter','das','quem','r','ap√≥s','s√£o','pode','√†','se','2025','n√£o','sim','por','na','do','no','da','dos','a','o','os','ele','ela','eles','elas','√©','com','um','uma','e','ou','quer','ao'}

import re
import csv

def carregar_dados(arquivo):

    dados = []
    with open(arquivo, 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            next(reader, None)
            for row in reader:
                if row:
                    dados.append(row[0])
            return dados

noticias_list = carregar_dados('noticias_cnn.csv')

def limpar_tokenizar(texto, ignorar_set):
    palavras = re.findall(r'\b\w+\b', texto.lower())
    return [p for p in palavras if p not in ignorar_set]


tokenized_noticias = []
for noticia in noticias_list:
    tokenized_noticias.append(limpar_tokenizar(noticia, ignorar))

print(tokenized_noticias)

from collections import Counter

palavrascont = Counter()
for frase in tokenized_noticias:
    palavrascont.update(frase)

top = palavrascont.most_common(10)

print(palavrascont)

print(top)

import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
import streamlit as st
import string


df = pd.read_csv('noticias_cnn.csv')
df['Data'] = pd.to_datetime(df.get('Data', pd.Timestamp.now()))


def limpar_texto(texto):
    texto = texto.lower()
    texto = texto.translate(str.maketrans('', '', string.punctuation))
    palavras = texto.split()
    return [p for p in palavras if p not in ignorar and len(p) > 2]

st.title("Palavras mais frequentes nas not√≠cias CNN")

modo = st.radio("Modo de an√°lise:", ["Geral", "Por dia"])
grafico = st.radio("Tipo de gr√°fico:", ["Colunas", "Barras horizontais"])
qtd = st.slider("Quantidade de palavras:", 5, 30, 10)

if modo == "Por dia":
    datas_disponiveis = df['Data'].dt.date.unique()
    data_escolhida = st.selectbox("Escolha uma data dispon√≠vel:", sorted(datas_disponiveis))
    df_filtrado = df[df['Data'].dt.date == data_escolhida]
else:
    df_filtrado = df


todas = []
for texto in df_filtrado["Not√≠cias"].dropna():
    todas.extend(limpar_texto(texto))

contagem = Counter(todas)
mais_comuns = contagem.most_common(qtd)

palavras, freq = zip(*mais_comuns)

fig, ax = plt.subplots()
if grafico == "Colunas":
    ax.bar(palavras, freq, color='skyblue')
    plt.xticks(rotation=45)
else:
    ax.barh(palavras, freq, color='salmon')
    ax.invert_yaxis()

st.pyplot(fig)

st.markdown("## Pesquisar ou comparar palavras espec√≠ficas")

opcao = st.radio("Tipo de busca:", ["Pesquisar uma palavra", "Comparar duas palavras"])

if opcao == "Pesquisar uma palavra":
    palavra = st.text_input("Digite a palavra para pesquisar").strip().lower()

    if palavra:
        if modo == "Por dia":
            total = sum([1 for noticia in df_filtrado["Not√≠cias"].dropna() if palavra in limpar_texto(noticia)])
        else:
            total = sum([1 for noticia in df["Not√≠cias"].dropna() if palavra in limpar_texto(noticia)])

        st.write(f"A palavra **{palavra}** apareceu em **{total}** not√≠cia(s).")

elif opcao == "Comparar duas palavras":
    palavra1 = st.text_input("Palavra 1").strip().lower()
    palavra2 = st.text_input("Palavra 2").strip().lower()

    if palavra1 and palavra2:
        if modo == "Por dia":
            textos = df_filtrado["Not√≠cias"].dropna()
        else:
            textos = df["Not√≠cias"].dropna()

        count1 = sum([1 for noticia in textos if palavra1 in limpar_texto(noticia)])
        count2 = sum([1 for noticia in textos if palavra2 in limpar_texto(noticia)])

        st.write(f"üìå **{palavra1}**: {count1} ocorr√™ncia(s)")
        st.write(f"üìå **{palavra2}**: {count2} ocorr√™ncia(s)")

        fig2, ax2 = plt.subplots()
        ax2.bar([palavra1, palavra2], [count1, count2], color=["mediumorchid", "gold"])
        ax2.set_ylabel("Frequ√™ncia")
        st.pyplot(fig2)

