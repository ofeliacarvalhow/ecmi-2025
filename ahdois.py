# -*- coding: utf-8 -*-
"""a2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n8egx0YHo4YGdKbYiK67cz02E2zOAsFO
"""
import requests
from bs4 import BeautifulSoup
import pandas as pd
import os
import csv
import re
from collections import Counter
import matplotlib.pyplot as plt
import streamlit as st
import string


st.markdown("""
<style>
    .stApp {
        background-image: url('https://raw.githubusercontent.com/ofeliacarvalhow/ecmi-2025/74550e7f84f783edd33a2e6f0ec260b9cf112078/fundodetela.jpg');
        background-size: cover;
        background-attachment: fixed;
    }

    html, body, [class*="css"], h1, h2, h3, h4, h5, h6, p, label, div, span,
    .stRadio, .stSelectbox, .stTextInput, .stSlider, .stMarkdown, .stDataFrame {
        color: black !important;
        background-color: transparent !important;
    }

    .custom-header {
        display: flex;
        justify-content: center;
        align-items: center;
        flex-direction: column;
        margin-bottom: 40px;
    }

    .custom-header h1 {
        font-size: 50px;
        margin: 0;
        text-align: center;
        color: black !important;
    }
</style>
<div class="custom-header">
    <h1>Palavras mais frequentes nas notícias CNN</h1>
    <img src="https://raw.githubusercontent.com/ofeliacarvalhow/ecmi-2025/74550e7f84f783edd33a2e6f0ec260b9cf112078/iconepng.png" width="70">
</div>
""", unsafe_allow_html=True)


def peganoticia():
    cnn = 'https://www.cnnbrasil.com.br/'
    response = requests.get(cnn, headers={'User-Agent': 'Mozilla/5.0'})
    soup = BeautifulSoup(response.content, 'html.parser')

    noticias = []
    for bagulho in soup.find_all(['a', 'h2', 'h3']):
        texto = bagulho.get_text(strip=True)
        if texto and len(texto) > 30 and texto not in noticias:
            noticias.append(texto)

    return noticias

def salvosim(novanoti, arquivo='noticias_cnn.csv'):
    if os.path.exists(arquivo):
        dfanti = pd.read_csv(arquivo)
        notianti = set(dfanti['Notícias'].tolist())
    else:
        dfanti = pd.DataFrame()
        notianti = set()

    unic = [noticia for noticia in novanoti if noticia not in notianti]

    if unic:
        dfnovo = pd.DataFrame({'Notícias': unic, 'Data': pd.Timestamp.now()})
        dfreal = pd.concat([dfanti, dfnovo], ignore_index=True) if notianti else dfnovo
        dfreal.to_csv(arquivo, index=False, encoding='utf-8-sig')

ignorar = {'de', 'em', 'que','para','sobre','novo','diz','veja','cnn','como','mais','ser','tem','nesta','até','entre','ter','das','quem','r','após','são','pode','à','se','2025','não','sim','por','na','do','no','da','dos','a','o','os','ele','ela','eles','elas','é','com','um','uma','e','ou','quer','ao'}

def carregar_dados(arquivo):
    dados = []
    with open(arquivo, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        next(reader, None)
        for row in reader:
            if row:
                dados.append(row[0])
        return dados

noticias = peganoticia()
salvosim(noticias)
noticias_list = carregar_dados('noticias_cnn.csv')

def limpar_tokenizar(texto, ignorar_set):
    palavras = re.findall(r'\b\w+\b', texto.lower())
    return [p for p in palavras if p not in ignorar_set]

def limpar_texto(texto):
    texto = texto.lower()
    texto = texto.translate(str.maketrans('', '', string.punctuation))
    palavras = texto.split()
    return [p for p in palavras if p not in ignorar and len(p) > 2]

tokenized_noticias = []
for noticia in noticias_list:
    tokenized_noticias.append(limpar_tokenizar(noticia, ignorar))

palavrascont = Counter()
for frase in tokenized_noticias:
    palavrascont.update(frase)

top = palavrascont.most_common(10)

df = pd.read_csv('noticias_cnn.csv')
if 'Data' not in df.columns:
    df['Data'] = pd.Timestamp.now()
else:
    df['Data'] = pd.to_datetime(df['Data'], errors='coerce')
df = df.dropna(subset=['Data'])

pagina = st.radio("Selecione o que você deseja visualizar:", ["Nada", "Palavras mais frequentes", "Pesquisar ou comparar palavras"])

if pagina == "Palavras mais frequentes":
    modo = st.radio("Modo de análise:", ["Nada", "Geral", "Por dia"], key="modo_palavras")

    if modo in ["Geral", "Por dia"]:
        grafico = st.radio("Tipo de gráfico:", ["Nada", "Colunas", "Barras horizontais", "Pizza"])
        qtd = st.slider("Quantidade de palavras:", 5, 30, 10)

        if grafico != "Nada":
            if modo == "Por dia":
                datas_disponiveis = sorted(df['Data'].dt.date.unique())
                data_escolhida = st.selectbox("Escolha uma data disponível:", datas_disponiveis)
                df_filtrado = df[df['Data'].dt.date == data_escolhida]
            else:
                df_filtrado = df

            todas = []
            for texto in df_filtrado["Notícias"].dropna():
                todas.extend(limpar_texto(texto))

            contagem = Counter(todas)
            mais_comuns = contagem.most_common(qtd)

            if mais_comuns:
                palavras, freq = zip(*mais_comuns)
                fig, ax = plt.subplots(figsize=(max(10, qtd), 6))
                if grafico == "Colunas":
                    ax.bar(palavras, freq, color='skyblue')
                    ax.set_xticklabels(palavras, rotation=45, ha='right')
                elif grafico == "Barras horizontais":
                    ax.barh(palavras, freq, color='salmon')
                    ax.invert_yaxis()
                elif grafico == "Pizza":
                    fig, ax = plt.subplots()
                    ax.pie(freq, labels=palavras, autopct='%1.1f%%')
                st.pyplot(fig)

elif pagina == "Pesquisar ou comparar palavras":
    modo = st.radio("Modo de análise:", ["Nada", "Geral", "Por dia"], key="modo2")

    if modo in ["Geral", "Por dia"]:
        if modo == "Por dia":
            datas_disponiveis = sorted(df['Data'].dt.date.unique())
            data_escolhida = st.selectbox("Escolha uma data disponível:", datas_disponiveis, key="data2")
            df_filtrado = df[df['Data'].dt.date == data_escolhida]
        else:
            df_filtrado = df

        opcao = st.radio("Tipo de busca:", ["Nada", "Pesquisar uma palavra", "Comparar duas palavras"])

        if opcao == "Pesquisar uma palavra":
            palavra = st.text_input("Digite a palavra para pesquisar").strip().lower()
            if palavra:
                textos = df_filtrado["Notícias"].dropna()
                total = sum([1 for noticia in textos if palavra in limpar_texto(noticia)])
                st.write(f"A palavra **{palavra}** apareceu em **{total}** notícia(s).")
                noticias_filtradas = [noticia for noticia in textos if palavra in limpar_texto(noticia)]
                if noticias_filtradas:
                    st.markdown("**Títulos contendo a palavra:**")
                    for n in noticias_filtradas:
                        st.markdown(f"- {n}")

        elif opcao == "Comparar duas palavras":
            palavra1 = st.text_input("Palavra 1").strip().lower()
            palavra2 = st.text_input("Palavra 2").strip().lower()
            tipo_grafico = st.radio("Tipo de gráfico para comparação:", ["Nada", "Colunas", "Pizza"], key="grafico_comparacao")

            if palavra1 and palavra2 and tipo_grafico != "Nada":
                textos = df_filtrado["Notícias"].dropna()
                count1 = sum([1 for noticia in textos if palavra1 in limpar_texto(noticia)])
                count2 = sum([1 for noticia in textos if palavra2 in limpar_texto(noticia)])

                st.write(f"{palavra1}: {count1} ocorrência(s)")
                st.write(f"{palavra2}: {count2} ocorrência(s)")

                fig2, ax2 = plt.subplots()
                if tipo_grafico == "Colunas":
                    ax2.bar([palavra1, palavra2], [count1, count2], color=["mediumorchid", "gold"])
                    ax2.set_ylabel("Frequência")
                else:
                    ax2.pie([count1, count2], labels=[palavra1, palavra2], autopct='%1.1f%%')
                st.pyplot(fig2)

                noticias1 = [noticia for noticia in textos if palavra1 in limpar_texto(noticia)]
                noticias2 = [noticia for noticia in textos if palavra2 in limpar_texto(noticia)]

                if noticias1:
                    st.markdown(f"**Títulos com {palavra1}:**")
                    for n in noticias1:
                        st.markdown(f"- {n}")

                if noticias2:
                    st.markdown(f"**Títulos com {palavra2}:**")
                    for n in noticias2:
                        st.markdown(f"- {n}")
